{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载本地env的key\n",
    "import dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# 添加异步处理\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [\n",
    "    \"./datasets/windows-wsl.pdf\",\n",
    "    \"./datasets/maiyouweng.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ./datasets/windows-wsl.pdf paper tool.\n",
      "Creating ./datasets/maiyouweng.pdf paper tool.\n"
     ]
    }
   ],
   "source": [
    "from utils import create_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Creating {paper} paper tool.\")\n",
    "    path = Path(paper)\n",
    "    vector_tool, summary_tool = await create_doc_tools(doc_name=path.stem, document_fp=path)\n",
    "    paper_to_tools_dict[path.stem] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'windows-wsl': [<llama_index.core.tools.query_engine.QueryEngineTool at 0x142a2a83fd0>,\n",
       "  <llama_index.core.tools.query_engine.QueryEngineTool at 0x142a2a83e50>],\n",
       " 'maiyouweng': [<llama_index.core.tools.query_engine.QueryEngineTool at 0x142a0f63b50>,\n",
       "  <llama_index.core.tools.query_engine.QueryEngineTool at 0x142a0f63af0>]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_to_tools_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A2A83FD0>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A2A83E50>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0F63B50>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0F63AF0>]\n"
     ]
    }
   ],
   "source": [
    "initial_tools = [t for paper in papers for t in paper_to_tools_dict[Path(paper).stem]]\n",
    "print(str(initial_tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: 卖油翁的中心思想是什么？卖油翁的故事对现代人有什么启发？什么是wsl2？\n",
      "=== Calling Function ===\n",
      "Calling function: maiyouweng_summary_query_engine_tool with args: {\"input\": \"\\u5356\\u6cb9\\u7fc1\\u7684\\u4e2d\\u5fc3\\u601d\\u60f3\\u662f\\u4ec0\\u4e48\\uff1f\"}\n",
      "=== Function Output ===\n",
      "熟能生巧，实践出真知。\n",
      "=== Calling Function ===\n",
      "Calling function: maiyouweng_summary_query_engine_tool with args: {\"input\": \"\\u5356\\u6cb9\\u7fc1\\u7684\\u6545\\u4e8b\\u5bf9\\u73b0\\u4ee3\\u4eba\\u6709\\u4ec0\\u4e48\\u542f\\u53d1\\uff1f\"}\n",
      "=== Function Output ===\n",
      "人应该谦虚虚心，不要自满自傲，要珍惜并学习他人的长处，努力提升自己的技能和能力。熟能生巧的道理告诉我们，只有通过不断的实践和努力，才能获得真正的技能和智慧。同时，要学会欣赏他人的才华，取长补短，不要轻视他人，也不要被自己的长处蒙蔽了双眼。\n",
      "=== Calling Function ===\n",
      "Calling function: windows-wsl_summary_query_engine_tool with args: {\"input\": \"\\u4ec0\\u4e48\\u662fwsl2\\uff1f\"}\n",
      "=== Function Output ===\n",
      "WSL 2 是适用于 Linux 的 Windows 子系统的第二个版本，它在 Windows 操作系统上提供了一个完整的 Linux 内核，使得可以在 Windows 上运行本机 Linux 容器。WSL 2 提供了更好的性能和更好的兼容性，使得在 Windows 上开发和运行 Linux 应用程序变得更加便捷和高效。\n",
      "=== LLM Response ===\n",
      "- 卖油翁的中心思想是“719能生巧，实习出真知”。这意味着人应该谦虚虚心，不要自满自负，要珍惜并学习他人的长处，努力提升自己的技能和能力。\n",
      "\n",
      "- 卖油翁的故事对现代人的启发是，只有通过不断的实习和努力，才能真正获得真正的技能和智慧。同时，要学会欣赏他人的才华，取长补短，不要轻视他人，也不要被自己的长处蒙蔽了双眼。\n",
      "\n",
      "- WSL 2是适用于 Linux 的 Windows 子系统的第二个版本，它在 Windows 操作系统上提供了一个完整的 Linux 内核，使得可以在 Windows 上运行本机 Linux 应用程序。WSL 2提供了更好的性能和更好的兼容性，使得在 Windows 上开发和运行 Linux 应用程序变得更加便捷和高效。\n",
      "- 卖油翁的中心思想是“719能生巧，实习出真知”。这意味着人应该谦虚虚心，不要自满自负，要珍惜并学习他人的长处，努力提升自己的技能和能力。\n",
      "\n",
      "- 卖油翁的故事对现代人的启发是，只有通过不断的实习和努力，才能真正获得真正的技能和智慧。同时，要学会欣赏他人的才华，取长补短，不要轻视他人，也不要被自己的长处蒙蔽了双眼。\n",
      "\n",
      "- WSL 2是适用于 Linux 的 Windows 子系统的第二个版本，它在 Windows 操作系统上提供了一个完整的 Linux 内核，使得可以在 Windows 上运行本机 Linux 应用程序。WSL 2提供了更好的性能和更好的兼容性，使得在 Windows 上开发和运行 Linux 应用程序变得更加便捷和高效。\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"卖油翁的中心思想是什么？\"\n",
    "    \"卖油翁的故事对现代人有什么启发？\"\n",
    "    \"什么是wsl2？\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [\n",
    "    \"./datasets/windows-wsl.pdf\",\n",
    "    \"./datasets/maiyouweng.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ./datasets/windows-wsl.pdf paper tool.\n",
      "Creating ./datasets/maiyouweng.pdf paper tool.\n"
     ]
    }
   ],
   "source": [
    "from utils import create_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "\n",
    "for paper in papers:\n",
    "    print(f\"Creating {paper} paper tool.\")\n",
    "    path = Path(paper)\n",
    "    vector_tool, summary_tool = await create_doc_tools(doc_name=path.stem, document_fp=path)\n",
    "    paper_to_tools_dict[path.stem] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0F285E0>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0F29660>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0AF7DC0>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0AF42B0>]\n"
     ]
    }
   ],
   "source": [
    "tools_list = [t for paper in papers for t in paper_to_tools_dict[Path(paper).stem]]\n",
    "print(str(tools_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    tools_list,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0F29660>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0AF42B0>, <llama_index.core.tools.query_engine.QueryEngineTool object at 0x00000142A0F285E0>]\n"
     ]
    }
   ],
   "source": [
    "retrieved_tools = obj_retriever.retrieve(\n",
    "    \"帮我写一个卖油翁的摘要\"\n",
    "    \"帮我写一个wsl的摘要\"\n",
    "    \"卖油翁的故事结合wsl，写一篇短文\"\n",
    ")\n",
    "print(str(retrieved_tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows-wsl_summary_query_engine_tool\n",
      "maiyouweng_summary_query_engine_tool\n",
      "windows-wsl_vector_query_engine_tool\n"
     ]
    }
   ],
   "source": [
    "for tool in retrieved_tools:\n",
    "    print(tool.metadata.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "你是一名人工智能代理，被编程为根据指定的文档集来回答问题。\n",
    "始终利用可用的工具来生成答案，确保回应直接基于提供的材料，而不是任何预先存在的知识。\n",
    "你所有的回应都应以Markdown文本格式呈现。\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: 帮我写一个卖油翁的摘要帮我写一个wsl的摘要卖油翁的故事结合wsl，写一篇短文\n",
      "=== Calling Function ===\n",
      "Calling function: maiyouweng_summary_query_engine_tool with args: {\"input\": \"\\u5356\\u6cb9\\u7fc1\\u7684\\u6545\\u4e8b\"}\n",
      "=== Function Output ===\n",
      "卖油翁是一个不卑不亢的劳动者形象，拥有熟练、精湛的沥油技巧。他具有平和豁达的心态，不对自己的技能骄傲自满，同时也深谙世事。在故事中，卖油翁通过展示他酌油的技艺，以此来揭示熟能生巧的道理。通过他的谦虚和技艺展示，卖油翁在故事中起着主导作用，引导陈尧咨认识到熟能生巧的重要性。\n",
      "=== Calling Function ===\n",
      "Calling function: windows-wsl_summary_query_engine_tool with args: {\"input\": \"wsl\"}\n",
      "=== Function Output ===\n",
      "WSL (Windows Subsystem for Linux) allows users to run Linux distributions directly on Windows, providing a Linux-compatible kernel interface. It enables access to Linux tools, applications, and command-line utilities within the Windows environment, bridging the gap between Windows and Linux operating systems.\n",
      "=== LLM Response ===\n",
      "卖油翁是一个不卑不亢的勤劳者形象，拥有熟练、精湛的油漆技巧。他具有平和谦达的心态，不对自己的技能傲慢自满，同时也深谙世事。在故事中，卖油翁通过展示他调油的技艺，以此展示熟能生巧的道理。通过他的诚虚和技艺展示，卖油翁在故事中起到主导作用，引导陈娠懂得认识到熟能生巧的重要性。\n",
      "\n",
      "而在现代科技中，WSL（Windows Subsystem for Linux）允许用户直接在Windows上运行Linux发行版，提供了Linux兼容的内核接口。它使用户可以在Windows环境中访问Linux工具、应用程序和命令行实用程序，弥合了Windows和Linux操作系统之间的差距。通过WSL，用户可以在Windows系统中体验到Linux的强大功能，实现了不同操作系统之间的互通和融合。\n",
      "卖油翁是一个不卑不亢的勤劳者形象，拥有熟练、精湛的油漆技巧。他具有平和谦达的心态，不对自己的技能傲慢自满，同时也深谙世事。在故事中，卖油翁通过展示他调油的技艺，以此展示熟能生巧的道理。通过他的诚虚和技艺展示，卖油翁在故事中起到主导作用，引导陈娠懂得认识到熟能生巧的重要性。\n",
      "\n",
      "而在现代科技中，WSL（Windows Subsystem for Linux）允许用户直接在Windows上运行Linux发行版，提供了Linux兼容的内核接口。它使用户可以在Windows环境中访问Linux工具、应用程序和命令行实用程序，弥合了Windows和Linux操作系统之间的差距。通过WSL，用户可以在Windows系统中体验到Linux的强大功能，实现了不同操作系统之间的互通和融合。\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"帮我写一个卖油翁的摘要\"\n",
    "    \"帮我写一个wsl的摘要\"\n",
    "    \"卖油翁的故事结合wsl，写一篇短文\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows-wsl_summary_query_engine_tool\n",
      "maiyouweng_summary_query_engine_tool\n",
      "windows-wsl_vector_query_engine_tool\n"
     ]
    }
   ],
   "source": [
    "for tool in retrieved_tools:\n",
    "    print(tool.metadata.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
